{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stanford Sentiment Analysis using LSTM RNN - Synonym Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfceefc56fbf476c8b57772c8eab8dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b50c9939c86f42ddb42a530deac69c6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8021654d5c2c4a83990754ef5dad3606",
              "IPY_MODEL_02d8acbce3de4145ab8e0c94dbd80b52"
            ]
          }
        },
        "b50c9939c86f42ddb42a530deac69c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8021654d5c2c4a83990754ef5dad3606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f969d0d7d697466b892f5523bb3b2051",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 239232,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 239232,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6140d79028e4ed9b01c4953abe44bb1"
          }
        },
        "02d8acbce3de4145ab8e0c94dbd80b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea4e8d2c99334fd794c2c5085a64a809",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 239232/239232 [00:00&lt;00:00, 327800.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e23c2c10e19a4f18a14017e2d8f57da2"
          }
        },
        "f969d0d7d697466b892f5523bb3b2051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6140d79028e4ed9b01c4953abe44bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea4e8d2c99334fd794c2c5085a64a809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e23c2c10e19a4f18a14017e2d8f57da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2977214328254bd28c156f23b9a9c0cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d5cb22720324f2f992f130ba8047ab6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e34ab4d0acc34ff380c84eee396105db",
              "IPY_MODEL_3f62a9dbb29c4c6999694ceba9a0ac63"
            ]
          }
        },
        "3d5cb22720324f2f992f130ba8047ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e34ab4d0acc34ff380c84eee396105db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7522e5b663314795902800bccc985f3b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11286,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11286,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07a815a415504f8aa9b26f1e628ac1ef"
          }
        },
        "3f62a9dbb29c4c6999694ceba9a0ac63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5dfbf36ed5624e58871b433758159217",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11286/11286 [19:33&lt;00:00,  9.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5e31f031966449b819d0824b827aca1"
          }
        },
        "7522e5b663314795902800bccc985f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07a815a415504f8aa9b26f1e628ac1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dfbf36ed5624e58871b433758159217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5e31f031966449b819d0824b827aca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajanm/END2_0_Session_5/blob/main/Stanford_Sentiment_Analysis_using_LSTM_RNN_Synonym_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Dataset Preview\n",
        "\n",
        "Your first step to deep learning in NLP. We will be mostly using PyTorch. Just like torchvision, PyTorch provides an official library, torchtext, for handling text-processing pipelines. \n",
        "\n",
        "We will be using previous session tweet dataset. Let's just preview the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Z2Q2rvdrKy",
        "outputId": "b4896df3-2fff-4702-9b55-4954c557f2de"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  8 03:51:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRcO_S7rcTr9"
      },
      "source": [
        "#!pip install pytreebank"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IclS7h8cNU-"
      },
      "source": [
        "# Load data\n",
        "#import pytreebank\n",
        "#import sys\n",
        "#import os\n",
        "\n",
        "#out_path = os.path.join(sys.path[0], 'sst_{}.txt')\n",
        "#dataset = pytreebank.load_sst('./raw_data')\n",
        "\n",
        "# Store train, dev and test in separate files\n",
        "#for category in ['train', 'test', 'dev']:\n",
        "#    with open(out_path.format(category), 'w') as outfile:\n",
        "#        for item in dataset[category]:\n",
        "#            outfile.write(\"__label__{}\\t{}\\n\".format(\n",
        "#                item.to_labeled_lines()[0][0] + 1,\n",
        "#                item.to_labeled_lines()[0][1]\n",
        "#            ))\n",
        "# Print the length of the training set\n",
        "#print(len(dataset['train']))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD2pSpTbUmaF",
        "outputId": "59910f85-9c6a-4e5f-c884-691313f961fe"
      },
      "source": [
        "!ls -alh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16K\n",
            "drwxr-xr-x 1 root root 4.0K Jun  1 13:40 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun  8 03:48 ..\n",
            "drwxr-xr-x 4 root root 4.0K Jun  1 13:40 .config\n",
            "drwxr-xr-x 1 root root 4.0K Jun  1 13:40 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ajW0C6qcmC-"
      },
      "source": [
        "#print(len(dataset['dev']))\n",
        "#print(len(dataset['test']))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0--BTAzKEg2T"
      },
      "source": [
        "TEXT_COL, LABEL_COL = 'text', 'label'\n",
        "DATASET_DIR = \"/content/\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DZ_Fl8ScAu5w",
        "outputId": "34f515b1-d89e-48af-e310-2742824cdd0c"
      },
      "source": [
        "!pip install nlpaug\n",
        "!pip install swifter"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f8/b11caecdd19aa2b1b2cb46c6cbbec692abd621aad884e653e459a8546add/nlpaug-1.1.3-py3-none-any.whl (394kB)\n",
            "\r\u001b[K     |▉                               | 10kB 24.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 28.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 19.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 71kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 81kB 11.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 204kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 215kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 225kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 235kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 245kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 256kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 266kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 276kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 286kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 296kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 307kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 317kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 327kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 337kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 348kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 358kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 368kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 378kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 389kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 399kB 9.2MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.3\n",
            "Collecting swifter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/3b/04bf42b94a22725241b47e0256458cde11f86f97572dd824e011f1ea8b20/swifter-1.0.7.tar.gz (633kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.1.5)\n",
            "Collecting psutil>=5.6.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/da/f7efdcf012b51506938553dbe302aecc22f3f43abd5cffa8320e8e0588d5/psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (2.12.0)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (4.41.1)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0cloudpickle>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from swifter) (7.6.3)\n",
            "Requirement already satisfied: parso>0.4.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (0.8.2)\n",
            "Requirement already satisfied: bleach>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from swifter) (3.3.0)\n",
            "Collecting modin[ray]>=0.8.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/87/118bc738470e51052162f744f3f7e0d9285f6e73be34b49f62c61ae1893d/modin-0.9.1-py3-none-manylinux1_x86_64.whl (579kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 22.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->swifter) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->swifter) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->swifter) (2.8.1)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.11.1)\n",
            "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/d2/d05466997f7751a2c06a7a416b7d1f131d765f7916698d3fdcb3a4d037e5/fsspec-2021.6.0-py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 27.9MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10; extra == \"dataframe\"\n",
            "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.0.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (3.5.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach>=3.1.1->swifter) (20.9)\n",
            "Collecting pyarrow==1.0; extra == \"ray\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/f4/a86a09ae9944ed3c10e2a628dee3e4c37b81f42063ab4f554d6962bc048d/pyarrow-1.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.2MB)\n",
            "\u001b[K     |████████████████████████████████| 17.2MB 171kB/s \n",
            "\u001b[?25hCollecting ray<1.2.0,>=1.0.0; extra == \"ray\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/bc/e1ae5b67cd8e0a4ca84f9a59b65b210daf4ed1d9ad69c035f1824aa1256f/ray-1.1.0-cp37-cp37m-manylinux2014_x86_64.whl (48.5MB)\n",
            "\u001b[K     |████████████████████████████████| 48.5MB 60kB/s \n",
            "\u001b[?25hCollecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (57.0.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.7.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.1.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach>=3.1.1->swifter) (2.4.7)\n",
            "Collecting colorful\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 41.4MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/59/12044123133d000f705383ad98579aeb0dd82d66b33a254a21b54bf0d6bb/opencensus-0.7.13-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 59.4MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.1MB/s \n",
            "\u001b[?25hCollecting aioredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n",
            "\u001b[?25hCollecting redis>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.0.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.12.4)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2.23.0)\n",
            "Collecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/4d/1a9cbe9a0b543e6733cb38afe26451522a9ef8e4897b59e74cc76838f245/py_spy-0.3.7-py2.py3-none-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 30.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.0.12)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.10.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.7.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (22.0.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.6.1)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.26.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (7.352.0)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Collecting hiredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/33/290cea35b09c80b4634773ad5572a8030a87b5d39736719f698f521d2a13/hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.9MB/s \n",
            "\u001b[?25hCollecting async-timeout\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.24.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 58.4MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 56.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.4.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (1.30.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (4.2.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray<1.2.0,>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter) (0.4.8)\n",
            "Building wheels for collected packages: swifter, gpustat\n",
            "  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for swifter: filename=swifter-1.0.7-cp37-none-any.whl size=13993 sha256=b9c8f15e62aa08e31528997d221353e798fc9cdbfc6dfd971b5f24cf7955481c\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/58/39/5b59c5f4d66ce67bf55f0178e0940c964e89e9f60d70376a37\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp37-none-any.whl size=12621 sha256=8d5aac7d6065618d7e50670e9cffe08f6436e411dd3bbfc5f9df7f7f695deb53\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "Successfully built swifter gpustat\n",
            "\u001b[31mERROR: modin 0.9.1 has requirement pandas==1.2.3, but you'll have pandas 1.1.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: psutil, pyarrow, colorful, opencensus-context, opencensus, colorama, blessings, gpustat, hiredis, async-timeout, aioredis, redis, multidict, yarl, aiohttp, aiohttp-cors, py-spy, ray, modin, swifter, fsspec, locket, partd\n",
            "  Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "Successfully installed aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 fsspec-2021.6.0 gpustat-0.6.0 hiredis-2.0.0 locket-0.2.1 modin-0.9.1 multidict-5.1.0 opencensus-0.7.13 opencensus-context-0.1.2 partd-1.2.0 psutil-5.8.0 py-spy-0.3.7 pyarrow-1.0.0 ray-1.1.0 redis-3.5.3 swifter-1.0.7 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AIwvweTBA9y",
        "outputId": "4eadd5bf-3f56-43d3-ff62-fca5a0ce1065"
      },
      "source": [
        "#download the stanford dataset to local storage for processing\n",
        "!wget http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 03:51:29--  http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip [following]\n",
            "--2021-06-08 03:51:29--  https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6372817 (6.1M) [application/zip]\n",
            "Saving to: ‘stanfordSentimentTreebank.zip’\n",
            "\n",
            "stanfordSentimentTr 100%[===================>]   6.08M  8.42MB/s    in 0.7s    \n",
            "\n",
            "2021-06-08 03:51:30 (8.42 MB/s) - ‘stanfordSentimentTreebank.zip’ saved [6372817/6372817]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEiB25qLBZbh",
        "outputId": "f7d944cc-e1d0-4fdd-ba47-24f2d90cb1fa"
      },
      "source": [
        "!unzip -o stanfordSentimentTreebank.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  stanfordSentimentTreebank.zip\n",
            "   creating: stanfordSentimentTreebank/\n",
            "  inflating: stanfordSentimentTreebank/datasetSentences.txt  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/stanfordSentimentTreebank/\n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSentences.txt  \n",
            "  inflating: stanfordSentimentTreebank/datasetSplit.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSplit.txt  \n",
            "  inflating: stanfordSentimentTreebank/dictionary.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._dictionary.txt  \n",
            "  inflating: stanfordSentimentTreebank/original_rt_snippets.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._original_rt_snippets.txt  \n",
            "  inflating: stanfordSentimentTreebank/README.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._README.txt  \n",
            "  inflating: stanfordSentimentTreebank/sentiment_labels.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._sentiment_labels.txt  \n",
            "  inflating: stanfordSentimentTreebank/SOStr.txt  \n",
            "  inflating: stanfordSentimentTreebank/STree.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV4f87ntBiJK",
        "outputId": "76fa9c44-46b5-43fe-e5d1-03dbffb9ae05"
      },
      "source": [
        "!ls -alh\n",
        "!ls -alh stanfordSentimentTreebank/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 6.2M\n",
            "drwxr-xr-x 1 root root 4.0K Jun  8 03:51 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun  8 03:48 ..\n",
            "drwxr-xr-x 4 root root 4.0K Jun  1 13:40 .config\n",
            "drwxrwxr-x 3 root root 4.0K Oct  9  2013 __MACOSX\n",
            "drwxr-xr-x 1 root root 4.0K Jun  1 13:40 sample_data\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9  2013 stanfordSentimentTreebank\n",
            "-rw-r--r-- 1 root root 6.1M Oct  9  2013 stanfordSentimentTreebank.zip\n",
            "total 20M\n",
            "drwxr-xr-x 2 root root 4.0K Oct  9  2013 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun  8 03:51 ..\n",
            "-rwxr-xr-x 1 root root 1.3M Oct  9  2013 datasetSentences.txt\n",
            "-rwxr-xr-x 1 root root  82K Oct  9  2013 datasetSplit.txt\n",
            "-rwxr-xr-x 1 root root  12M Oct  9  2013 dictionary.txt\n",
            "-rwxr-xr-x 1 root root 1.2M Feb  2  2013 original_rt_snippets.txt\n",
            "-rwxr-xr-x 1 root root 2.4K Oct  9  2013 README.txt\n",
            "-rwxr-xr-x 1 root root 3.2M Oct  9  2013 sentiment_labels.txt\n",
            "-rwxr-xr-x 1 root root 1.2M Feb  2  2013 SOStr.txt\n",
            "-rwxr-xr-x 1 root root 1.3M Feb  2  2013 STree.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9wwO8naBpGX"
      },
      "source": [
        "#import all libraries required for the notebook\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#import nlp augumenter library\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n",
        "import swifter\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HrGtHIaBxIO"
      },
      "source": [
        "#set data directory\n",
        "data_dir = 'stanfordSentimentTreebank'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUKTs2GWB1m5"
      },
      "source": [
        "#load sentiment labels\n",
        "sentiment_labels = pd.read_csv(os.path.join(data_dir, \"sentiment_labels.txt\"), names=['phrase_ids', 'sentiment_values'], sep=\"|\", header=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "w-ueXVJNB5q9",
        "outputId": "ef6726df-a3ac-4bda-a1af-efc6129a04c5"
      },
      "source": [
        "#sample the sentiment labels data - 10 rows\n",
        "sentiment_labels.head(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.37500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.41667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.54167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.33333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.45833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase_ids  sentiment_values\n",
              "0           0           0.50000\n",
              "1           1           0.50000\n",
              "2           2           0.44444\n",
              "3           3           0.50000\n",
              "4           4           0.42708\n",
              "5           5           0.37500\n",
              "6           6           0.41667\n",
              "7           7           0.54167\n",
              "8           8           0.33333\n",
              "9           9           0.45833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jWdA2PpB_ci"
      },
      "source": [
        "# function to convert label (sentiment value) to 5 classes\n",
        "# for very negative, negative, neutral, positive, very positive\n",
        "def discretize_label(label):\n",
        "    # very negative\n",
        "    if label <= 0.2: return 0\n",
        "    # negative\n",
        "    if label <= 0.4: return 1\n",
        "    # neutral\n",
        "    if label <= 0.6: return 2\n",
        "    # positive\n",
        "    if label <= 0.8: return 3\n",
        "    # very positive\n",
        "    return 4"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "cfceefc56fbf476c8b57772c8eab8dde",
            "b50c9939c86f42ddb42a530deac69c6f",
            "8021654d5c2c4a83990754ef5dad3606",
            "02d8acbce3de4145ab8e0c94dbd80b52",
            "f969d0d7d697466b892f5523bb3b2051",
            "b6140d79028e4ed9b01c4953abe44bb1",
            "ea4e8d2c99334fd794c2c5085a64a809",
            "e23c2c10e19a4f18a14017e2d8f57da2"
          ]
        },
        "id": "1VfpWgAXCD9R",
        "outputId": "6b5de1ae-7222-4fa7-ffa2-89c747500641"
      },
      "source": [
        "sentiment_labels['sentiment_values'] = sentiment_labels['sentiment_values'].progress_apply(discretize_label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfceefc56fbf476c8b57772c8eab8dde",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=239232.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "A47M9fhxCIsP",
        "outputId": "0decb74d-be15-4fbf-d891-27a861f3b2e1"
      },
      "source": [
        "#sample the sentiment labels data - 10 rows - after converting labels to classes\n",
        "sentiment_labels.head(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase_ids  sentiment_values\n",
              "0           0                 2\n",
              "1           1                 2\n",
              "2           2                 2\n",
              "3           3                 2\n",
              "4           4                 2\n",
              "5           5                 1\n",
              "6           6                 2\n",
              "7           7                 2\n",
              "8           8                 1\n",
              "9           9                 2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "mOhyBy7BCM14",
        "outputId": "0eed32a4-fae4-4416-eddc-0b5208fe8734"
      },
      "source": [
        "#load the sentences\n",
        "sentence_ids = pd.read_csv(os.path.join(data_dir, \"datasetSentences.txt\"), sep=\"\\t\")\n",
        "sentence_ids.head(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Perhaps no picture ever made has more literall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Steers turns in a snappy screenplay that curls...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>But he somehow pulls it off .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index                                           sentence\n",
              "0               1  The Rock is destined to be the 21st Century 's...\n",
              "1               2  The gorgeously elaborate continuation of `` Th...\n",
              "2               3                     Effective but too-tepid biopic\n",
              "3               4  If you sometimes like to go to the movies to h...\n",
              "4               5  Emerges as something rare , an issue movie tha...\n",
              "5               6  The film provides some great insight into the ...\n",
              "6               7  Offers that rare combination of entertainment ...\n",
              "7               8  Perhaps no picture ever made has more literall...\n",
              "8               9  Steers turns in a snappy screenplay that curls...\n",
              "9              10                      But he somehow pulls it off ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "YaQC2DV_CRvi",
        "outputId": "a23ad12a-bd8e-4160-d88d-d3754597e550"
      },
      "source": [
        "#load the dictionary and sample 10 rows\n",
        "dictionary = pd.read_csv(os.path.join(data_dir, \"dictionary.txt\"), sep=\"|\", names=['phrase', 'phrase_ids'])\n",
        "dictionary.head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>phrase_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! '</td>\n",
              "      <td>22935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! ''</td>\n",
              "      <td>18235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Alas</td>\n",
              "      <td>179257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant</td>\n",
              "      <td>22936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>! Brilliant !</td>\n",
              "      <td>40532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>! Brilliant ! '</td>\n",
              "      <td>22937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>! C'mon</td>\n",
              "      <td>60624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>! Gollum 's ` performance ' is incredible</td>\n",
              "      <td>13402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>! Oh , look at that clever angle ! Wow , a jum...</td>\n",
              "      <td>179258</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              phrase  phrase_ids\n",
              "0                                                  !           0\n",
              "1                                                ! '       22935\n",
              "2                                               ! ''       18235\n",
              "3                                             ! Alas      179257\n",
              "4                                        ! Brilliant       22936\n",
              "5                                      ! Brilliant !       40532\n",
              "6                                    ! Brilliant ! '       22937\n",
              "7                                            ! C'mon       60624\n",
              "8          ! Gollum 's ` performance ' is incredible       13402\n",
              "9  ! Oh , look at that clever angle ! Wow , a jum...      179258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "RJTBQUdxCa70",
        "outputId": "ab24420d-e906-44d9-f555-7f2973965585"
      },
      "source": [
        "#load the train/test data and sample 10 rows\n",
        "train_test_split = pd.read_csv(os.path.join(data_dir, \"datasetSplit.txt\"))\n",
        "train_test_split.head(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>splitset_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  splitset_label\n",
              "0               1               1\n",
              "1               2               1\n",
              "2               3               2\n",
              "3               4               2\n",
              "4               5               2\n",
              "5               6               2\n",
              "6               7               2\n",
              "7               8               2\n",
              "8               9               2\n",
              "9              10               2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs13yIFTCfJM"
      },
      "source": [
        "sentence_phrase_merge = pd.merge(sentence_ids, dictionary, left_on='sentence', right_on='phrase')\n",
        "sentence_phrase_split = pd.merge(sentence_phrase_merge, train_test_split, on='sentence_index')\n",
        "input_dataset = pd.merge(sentence_phrase_split, sentiment_labels, on='phrase_ids')\n",
        "input_dataset['phrase_cleaned'] = input_dataset['sentence'].str.replace(r\"\\s('s|'d|'re|'ll|'m|'ve|n't)\\b\", lambda m: m.group(1))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hYQk7iWnCkV2",
        "outputId": "fc7f384a-5e96-4497-f8a9-a5d6f5f03818"
      },
      "source": [
        "input_dataset.describe()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>splitset_label</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11286.000000</td>\n",
              "      <td>11286.000000</td>\n",
              "      <td>11286.000000</td>\n",
              "      <td>11286.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5910.961102</td>\n",
              "      <td>132003.589846</td>\n",
              "      <td>1.373294</td>\n",
              "      <td>2.059986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3422.455572</td>\n",
              "      <td>68214.626430</td>\n",
              "      <td>0.647295</td>\n",
              "      <td>1.287835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3467.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2951.250000</td>\n",
              "      <td>67402.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5904.500000</td>\n",
              "      <td>144063.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8865.750000</td>\n",
              "      <td>188139.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>11855.000000</td>\n",
              "      <td>238977.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index     phrase_ids  splitset_label  sentiment_values\n",
              "count    11286.000000   11286.000000    11286.000000      11286.000000\n",
              "mean      5910.961102  132003.589846        1.373294          2.059986\n",
              "std       3422.455572   68214.626430        0.647295          1.287835\n",
              "min          1.000000    3467.000000        1.000000          0.000000\n",
              "25%       2951.250000   67402.000000        1.000000          1.000000\n",
              "50%       5904.500000  144063.500000        1.000000          2.000000\n",
              "75%       8865.750000  188139.750000        2.000000          3.000000\n",
              "max      11855.000000  238977.000000        3.000000          4.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cOoxMVvCl-w",
        "outputId": "5d2fd79c-4a56-4ffa-b87c-a5e03c84d101"
      },
      "source": [
        "input_dataset.info()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11286 entries, 0 to 11285\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   sentence_index    11286 non-null  int64 \n",
            " 1   sentence          11286 non-null  object\n",
            " 2   phrase            11286 non-null  object\n",
            " 3   phrase_ids        11286 non-null  int64 \n",
            " 4   splitset_label    11286 non-null  int64 \n",
            " 5   sentiment_values  11286 non-null  int64 \n",
            " 6   phrase_cleaned    11286 non-null  object\n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 705.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "Dgb8V7ioCtrA",
        "outputId": "4e62d2ae-213d-4146-a36c-71ed1f2c7394"
      },
      "source": [
        "input_dataset.head(10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase</th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>splitset_label</th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>phrase_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "      <td>14498</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "      <td>14351</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Perhaps no picture ever made has more literall...</td>\n",
              "      <td>Perhaps no picture ever made has more literall...</td>\n",
              "      <td>14371</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Perhaps no picture ever made has more literall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Steers turns in a snappy screenplay that curls...</td>\n",
              "      <td>Steers turns in a snappy screenplay that curls...</td>\n",
              "      <td>225968</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Steers turns in a snappy screenplay that curls...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>But he somehow pulls it off .</td>\n",
              "      <td>But he somehow pulls it off .</td>\n",
              "      <td>222746</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>But he somehow pulls it off .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ...                                     phrase_cleaned\n",
              "0               1  ...  The Rock is destined to be the 21st Century's ...\n",
              "1               2  ...  The gorgeously elaborate continuation of `` Th...\n",
              "2               3  ...                     Effective but too-tepid biopic\n",
              "3               4  ...  If you sometimes like to go to the movies to h...\n",
              "4               5  ...  Emerges as something rare , an issue movie tha...\n",
              "5               6  ...  The film provides some great insight into the ...\n",
              "6               7  ...  Offers that rare combination of entertainment ...\n",
              "7               8  ...  Perhaps no picture ever made has more literall...\n",
              "8               9  ...  Steers turns in a snappy screenplay that curls...\n",
              "9              10  ...                      But he somehow pulls it off .\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2977214328254bd28c156f23b9a9c0cf",
            "3d5cb22720324f2f992f130ba8047ab6",
            "e34ab4d0acc34ff380c84eee396105db",
            "3f62a9dbb29c4c6999694ceba9a0ac63",
            "7522e5b663314795902800bccc985f3b",
            "07a815a415504f8aa9b26f1e628ac1ef",
            "5dfbf36ed5624e58871b433758159217",
            "a5e31f031966449b819d0824b827aca1"
          ]
        },
        "id": "pyBfG-xmCzS6",
        "outputId": "8e885c93-8bd2-4847-beb2-08e623f71e77"
      },
      "source": [
        "output_dataset = input_dataset.copy()\n",
        "input_dataset_aug_synonym = input_dataset.copy()\n",
        "aug_synonym = naw.SynonymAug(aug_src='wordnet')\n",
        "synonym_sentences = input_dataset_aug_synonym['sentence'].progress_apply(aug_synonym.augment)\n",
        "#synonym_sentences = input_dataset_aug_synonym['sentence'].swifter.set_npartitions(6).progress_bar(True).apply(aug_synonym.augment)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2977214328254bd28c156f23b9a9c0cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11286.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hyrEFIyHC8Bh",
        "outputId": "db203d9f-0e02-4c0a-d45e-f0014d7cd0b1"
      },
      "source": [
        "output_dataset.describe()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>splitset_label</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11286.000000</td>\n",
              "      <td>11286.000000</td>\n",
              "      <td>11286.000000</td>\n",
              "      <td>11286.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5910.961102</td>\n",
              "      <td>132003.589846</td>\n",
              "      <td>1.373294</td>\n",
              "      <td>2.059986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3422.455572</td>\n",
              "      <td>68214.626430</td>\n",
              "      <td>0.647295</td>\n",
              "      <td>1.287835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3467.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2951.250000</td>\n",
              "      <td>67402.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5904.500000</td>\n",
              "      <td>144063.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8865.750000</td>\n",
              "      <td>188139.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>11855.000000</td>\n",
              "      <td>238977.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index     phrase_ids  splitset_label  sentiment_values\n",
              "count    11286.000000   11286.000000    11286.000000      11286.000000\n",
              "mean      5910.961102  132003.589846        1.373294          2.059986\n",
              "std       3422.455572   68214.626430        0.647295          1.287835\n",
              "min          1.000000    3467.000000        1.000000          0.000000\n",
              "25%       2951.250000   67402.000000        1.000000          1.000000\n",
              "50%       5904.500000  144063.500000        1.000000          2.000000\n",
              "75%       8865.750000  188139.750000        2.000000          3.000000\n",
              "max      11855.000000  238977.000000        3.000000          4.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5-BaGQZC9z9",
        "outputId": "2793f57c-4481-4299-c476-2e6d5e33e893"
      },
      "source": [
        "synonym_sentences.head(10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The Rock embody destined to cost the twenty fi...\n",
              "1    The resplendently elaborate continuation of ` ...\n",
              "2                     In effect but too - tepid biopic\n",
              "3    If you sometimes corresponding to live on to t...\n",
              "4    Emerges as something rare, an issue moving pic...\n",
              "5    The film provides some heavy sixth sense into ...\n",
              "6    Offers that rare combination of entertainment ...\n",
              "7    Perhaps no picture ever so made has to a great...\n",
              "8    Steers turns in a jaunty screenplay that curls...\n",
              "9     But he someway pulls information technology off.\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "C4jqYxSxDFzp",
        "outputId": "ac270d64-0f4e-4587-a1d6-f0f0f7947bf4"
      },
      "source": [
        "input_dataset_aug_synonym['sentence'] = synonym_sentences\n",
        "input_dataset_aug_synonym.head(10)\n",
        "#input_dataset_aug_synonym.to_csv('sst_input_dataset_aug_synonym.csv')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase</th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>splitset_label</th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>phrase_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock embody destined to cost the twenty fi...</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The resplendently elaborate continuation of ` ...</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>In effect but too - tepid biopic</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes corresponding to live on to t...</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare, an issue moving pic...</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>The film provides some heavy sixth sense into ...</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "      <td>14498</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "      <td>14351</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Perhaps no picture ever so made has to a great...</td>\n",
              "      <td>Perhaps no picture ever made has more literall...</td>\n",
              "      <td>14371</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Perhaps no picture ever made has more literall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Steers turns in a jaunty screenplay that curls...</td>\n",
              "      <td>Steers turns in a snappy screenplay that curls...</td>\n",
              "      <td>225968</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Steers turns in a snappy screenplay that curls...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>But he someway pulls information technology off.</td>\n",
              "      <td>But he somehow pulls it off .</td>\n",
              "      <td>222746</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>But he somehow pulls it off .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ...                                     phrase_cleaned\n",
              "0               1  ...  The Rock is destined to be the 21st Century's ...\n",
              "1               2  ...  The gorgeously elaborate continuation of `` Th...\n",
              "2               3  ...                     Effective but too-tepid biopic\n",
              "3               4  ...  If you sometimes like to go to the movies to h...\n",
              "4               5  ...  Emerges as something rare , an issue movie tha...\n",
              "5               6  ...  The film provides some great insight into the ...\n",
              "6               7  ...  Offers that rare combination of entertainment ...\n",
              "7               8  ...  Perhaps no picture ever made has more literall...\n",
              "8               9  ...  Steers turns in a snappy screenplay that curls...\n",
              "9              10  ...                      But he somehow pulls it off .\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "NSX9hF_XDKUf",
        "outputId": "a77a2b55-1c99-4fd1-f1ee-0eb376f925fb"
      },
      "source": [
        "output_dataset = output_dataset.append(input_dataset_aug_synonym)\n",
        "output_dataset.describe()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>splitset_label</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22572.000000</td>\n",
              "      <td>22572.000000</td>\n",
              "      <td>22572.000000</td>\n",
              "      <td>22572.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5910.961102</td>\n",
              "      <td>132003.589846</td>\n",
              "      <td>1.373294</td>\n",
              "      <td>2.059986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3422.379755</td>\n",
              "      <td>68213.115301</td>\n",
              "      <td>0.647281</td>\n",
              "      <td>1.287807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3467.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2951.000000</td>\n",
              "      <td>67392.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5904.500000</td>\n",
              "      <td>144063.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8866.000000</td>\n",
              "      <td>188141.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>11855.000000</td>\n",
              "      <td>238977.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index     phrase_ids  splitset_label  sentiment_values\n",
              "count    22572.000000   22572.000000    22572.000000      22572.000000\n",
              "mean      5910.961102  132003.589846        1.373294          2.059986\n",
              "std       3422.379755   68213.115301        0.647281          1.287807\n",
              "min          1.000000    3467.000000        1.000000          0.000000\n",
              "25%       2951.000000   67392.000000        1.000000          1.000000\n",
              "50%       5904.500000  144063.500000        1.000000          2.000000\n",
              "75%       8866.000000  188141.000000        2.000000          3.000000\n",
              "max      11855.000000  238977.000000        3.000000          4.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjbB9gGUDN5N"
      },
      "source": [
        "output_dataset['label'] = '__label__' + output_dataset['sentiment_values'].map(str) \n",
        "#output_dataset.to_csv('sst_output_dataset1.csv')\n",
        "header = ['label', 'sentence']\n",
        "#output_dataset.to_csv('sst_output_dataset1.txt', sep ='\\t', \n",
        "#                      columns=header, index=False, header=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOgq-PiNDinA"
      },
      "source": [
        "# create the train, dev and test datasets in a 60%, 40%, 40% split randomly\n",
        "import numpy as np\n",
        "\n",
        "train_output_dataset, dev_output_dataset, test_output_dataset = \\\n",
        "              np.split(output_dataset.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(output_dataset)), int(.8*len(output_dataset))])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sktny-kjDsTl"
      },
      "source": [
        "train_output_dataset.to_csv('sst_train.txt', sep ='\\t', \n",
        "                      columns=header, index=False, header=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiKPXJ7FDwNU"
      },
      "source": [
        "dev_output_dataset.to_csv('sst_dev.txt', sep ='\\t', \n",
        "                      columns=header, index=False, header=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6a6HUUUDzG9"
      },
      "source": [
        "test_output_dataset.to_csv('sst_test.txt', sep ='\\t', \n",
        "                      columns=header, index=False, header=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf1RwYNHHuYK",
        "outputId": "99e533c6-1a03-438e-e495-0d96f0a471af"
      },
      "source": [
        "!ls -alh *.txt"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 516K Jun  8 04:11 sst_dev.txt\n",
            "-rw-r--r-- 1 root root 517K Jun  8 04:11 sst_test.txt\n",
            "-rw-r--r-- 1 root root 1.6M Jun  8 04:11 sst_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyzRffg8EaVE"
      },
      "source": [
        "def read_sst5(data_dir, colnames=[LABEL_COL, TEXT_COL]):\n",
        "    datasets = {}\n",
        "    for t in [\"train\", \"dev\", \"test\"]:\n",
        "        df = pd.read_csv(os.path.join(data_dir, f\"sst_{t}.txt\"), sep='\\t', header=None, names=colnames)\n",
        "        df[LABEL_COL] = df[LABEL_COL].str.replace('__label__', '')\n",
        "        df[LABEL_COL] = df[LABEL_COL].astype(int)   # Categorical data type for truth labels\n",
        "        df[LABEL_COL] = df[LABEL_COL] - 1  # Zero-index labels for PyTorch\n",
        "        datasets[t] = df\n",
        "    return datasets"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O_HDEfKEqTR",
        "outputId": "82a92eee-f68a-4452-ccd1-5b9af480c672"
      },
      "source": [
        "data_dict=read_sst5(DATASET_DIR , colnames=[LABEL_COL,TEXT_COL])\n",
        "data_dict"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev':       label                                               text\n",
              " 0        -1  You calcium n ' t believe anyone would very bu...\n",
              " 1         2  I wish that Smith, he ' s not making fun of th...\n",
              " 2         2  So, too, be this comedy astir balmy culture cl...\n",
              " 3         3  It 's a head-turner -- thoughtfully written , ...\n",
              " 4         0  can personify every bit tiresome as 9 seconds ...\n",
              " ...     ...                                                ...\n",
              " 4509      2  The best revenge may just be living well becau...\n",
              " 4510      2   The bottom line is the piece works brilliantly .\n",
              " 4511      2  Unfolds in a series of achronological vignette...\n",
              " 4512      2  Intriguing and beautiful film , but those of y...\n",
              " 4513      1  Information technology was a iniquity and stor...\n",
              " \n",
              " [4514 rows x 2 columns],\n",
              " 'test':       label                                               text\n",
              " 0         0  For a shoot - ' pica em - upward, Ballistic is...\n",
              " 1         2  Information technology seem like Iodine have c...\n",
              " 2         2  Elaborate peculiar effects take centre cover, ...\n",
              " 3         1  Has all the pathos of a Assay mark scorecard a...\n",
              " 4         3  A sensational while of visual verse that will,...\n",
              " ...     ...                                                ...\n",
              " 4510      2  Their computer - animated faces be very expres...\n",
              " 4511      1  One of those based - on - truth stories that p...\n",
              " 4512      3  A fresh , entertaining comedy that looks at re...\n",
              " 4513      2  Achieves a sort of filmic epiphany that revels...\n",
              " 4514      3         The film be small in scope, yet dead make.\n",
              " \n",
              " [4515 rows x 2 columns],\n",
              " 'train':        label                                               text\n",
              " 0         -1  ... a complete shambles of a movie so sloppy ,...\n",
              " 1          0  Solondz may be win over that he has something ...\n",
              " 2          0  The Good Girl is a film in which the talent is...\n",
              " 3          0            You could hate it for the same reason .\n",
              " 4          3  Arliss Howard 's ambitious , moving , and adve...\n",
              " ...      ...                                                ...\n",
              " 13538      3    His work with histrion is particularly telling.\n",
              " 13539      2  If you answered yes , by all means enjoy The N...\n",
              " 13540      0  It deficiency of quality earn it a place aboar...\n",
              " 13541      2  Similar information technology claim character...\n",
              " 13542      0  Too ungainly in key moments. .. to ready a big...\n",
              " \n",
              " [13543 rows x 2 columns]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "kqOW0TSfGHKa",
        "outputId": "381c3c6b-72f9-4a38-ae2d-cfdace734ee6"
      },
      "source": [
        "data_dict['train'].head(10)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>... a complete shambles of a movie so sloppy ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Solondz may be win over that he has something ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The Good Girl is a film in which the talent is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>You could hate it for the same reason .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Arliss Howard 's ambitious , moving , and adve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-1</td>\n",
              "      <td>This is the sort of low-grade dreck that usual...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>`` its successes are also tempered with elemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>A beautiful , entertaining two hours .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>The cast delivers without sham the raw-nerved ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>Cherry red Orchard be naughtily edited, often ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0     -1  ... a complete shambles of a movie so sloppy ,...\n",
              "1      0  Solondz may be win over that he has something ...\n",
              "2      0  The Good Girl is a film in which the talent is...\n",
              "3      0            You could hate it for the same reason .\n",
              "4      3  Arliss Howard 's ambitious , moving , and adve...\n",
              "5     -1  This is the sort of low-grade dreck that usual...\n",
              "6      1  `` its successes are also tempered with elemen...\n",
              "7      3             A beautiful , entertaining two hours .\n",
              "8      2  The cast delivers without sham the raw-nerved ...\n",
              "9      0  Cherry red Orchard be naughtily edited, often ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoWXB04gGPme",
        "outputId": "a7fbdf9d-d772-467e-d264-577d00274e31"
      },
      "source": [
        "data_dict['train'].shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13543, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "qS_vrk_pFUla",
        "outputId": "465cb856-b47a-4a89-8628-988a2889fbfc"
      },
      "source": [
        "data_dict['dev'].head(10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>You calcium n ' t believe anyone would very bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>I wish that Smith, he ' s not making fun of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>So, too, be this comedy astir balmy culture cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>It 's a head-turner -- thoughtfully written , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>can personify every bit tiresome as 9 seconds ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>- I as well wanted a little unknown as a suppo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>But he loses his focus when he concentrates on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>Ca n't get enough of libidinous young city dwe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>My Big Fat Greek Wedding is not only the best ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>Formulaic to the 51st power , more like .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0     -1  You calcium n ' t believe anyone would very bu...\n",
              "1      2  I wish that Smith, he ' s not making fun of th...\n",
              "2      2  So, too, be this comedy astir balmy culture cl...\n",
              "3      3  It 's a head-turner -- thoughtfully written , ...\n",
              "4      0  can personify every bit tiresome as 9 seconds ...\n",
              "5      2  - I as well wanted a little unknown as a suppo...\n",
              "6      0  But he loses his focus when he concentrates on...\n",
              "7      1  Ca n't get enough of libidinous young city dwe...\n",
              "8      3  My Big Fat Greek Wedding is not only the best ...\n",
              "9      0          Formulaic to the 51st power , more like ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPT65s9hGZwK",
        "outputId": "8abed769-31f4-4107-cfaf-2263ded70b25"
      },
      "source": [
        "data_dict['dev'].shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4514, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g65vaGbp5VZs",
        "outputId": "6504d032-e367-4e4b-9318-f3e500a7e5fe"
      },
      "source": [
        "data_dict['test'].shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4515, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-YLiyYk5Yc9",
        "outputId": "47523a38-37b0-43f5-938c-028106714d39"
      },
      "source": [
        "data_dict['train'].label.value_counts()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    3516\n",
              " 2    3515\n",
              " 1    2648\n",
              " 3    2130\n",
              "-1    1734\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63g08ijOrf7"
      },
      "source": [
        "Now we shall be defining LABEL as a LabelField, which is a subclass of Field that sets sequential to False (as it’s our numerical category class). Text is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk8IP4SK1Lrp",
        "outputId": "ffce0f62-db63-4549-80ca-76ce105f6561"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import legacy\n",
        "from torchtext.legacy import data\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f724f2f93b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Text = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)#Defines a datatype together with instructions for converting to Tensor.\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-lYIe_O7Vy"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMDBHQ9v6-nl"
      },
      "source": [
        "fields=[('text',Text),('label',Label)]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtZ-Ph2P1xL"
      },
      "source": [
        "Armed with our declared fields, lets convert from pandas to list to torchtext. We could also use TabularDataset to apply that definition to the CSV directly but showing an alternative approach too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIiHKLQU8al_"
      },
      "source": [
        "example_train=[data.Example.fromlist([data_dict['train'].text[i],data_dict['train'].label[i]],fields) for i in range (data_dict['train'].shape[0])]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating training dataset\n",
        "train = data.Dataset(example_train, fields)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpmKkoIO8vEO"
      },
      "source": [
        "Similarly, perform the above step for validation (dev) dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuQjKsfII_rL"
      },
      "source": [
        "example_dev=[data.Example.fromlist([data_dict['dev'].text[i],data_dict['dev'].label[i]],fields) for i in range (data_dict['dev'].shape[0])]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVPITjbYJq4n"
      },
      "source": [
        "# Creating dev/validation dataset\n",
        "dev = data.Dataset(example_dev, fields)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLuAavz4JBO3",
        "outputId": "f6bd626e-9855-40bd-d2d5-4530028e1486"
      },
      "source": [
        "train, dev"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torchtext.legacy.data.dataset.Dataset at 0x7f71e04b2f90>,\n",
              " <torchtext.legacy.data.dataset.Dataset at 0x7f71dfd5fb10>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykvsCGQMR6UD",
        "outputId": "f1bbc5eb-b35b-487c-95c1-41acf27596a3"
      },
      "source": [
        "(len(train),len(dev))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13543, 4514)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kix8P2IKSBaV"
      },
      "source": [
        "An example from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUpEOQruR9JL",
        "outputId": "5b976566-0e35-43c8-ff1d-0cc8a82a94cc"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'text': ['The',\n",
              "  'pretensions',\n",
              "  '--',\n",
              "  'and',\n",
              "  'disposable',\n",
              "  'story',\n",
              "  '--',\n",
              "  'sink',\n",
              "  'the',\n",
              "  'movie',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVlspHSKJ7Df",
        "outputId": "437c8b72-5cd7-4137-f49b-5ac760b6e2c6"
      },
      "source": [
        "vars(dev.examples[10])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3,\n",
              " 'text': ['Nolan',\n",
              "  'bear',\n",
              "  'witness',\n",
              "  'that',\n",
              "  'he',\n",
              "  'toilet',\n",
              "  'cross',\n",
              "  'sword',\n",
              "  'with',\n",
              "  'the',\n",
              "  'good',\n",
              "  'of',\n",
              "  'them',\n",
              "  'and',\n",
              "  'helm',\n",
              "  'a',\n",
              "  'more',\n",
              "  'traditionally',\n",
              "  'plotted',\n",
              "  'popcorn',\n",
              "  'thriller',\n",
              "  'while',\n",
              "  'surrendering',\n",
              "  'little',\n",
              "  'of',\n",
              "  'his',\n",
              "  'intellectual',\n",
              "  'rigor',\n",
              "  'operating',\n",
              "  'theatre',\n",
              "  'creative',\n",
              "  'composure',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvWQ-SpSmSz"
      },
      "source": [
        "At this point we would have built a one-hot encoding of each word that is present in the dataset—a rather tedious process. Thankfully, torchtext will do this for us, and will also allow a max_size parameter to be passed in to limit the vocabulary to the most common words. This is normally done to prevent the construction of a huge, memory-hungry model. We don’t want our GPUs too overwhelmed, after all. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukXt8VfvKKp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400b3033-296d-4b2b-e971-513447621ae4"
      },
      "source": [
        "Text.build_vocab(train, vectors = \"glove.6B.300d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.39MB/s]                           \n",
            "100%|█████████▉| 399270/400000 [00:34<00:00, 11551.27it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyEeEjXTGhX"
      },
      "source": [
        "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsOUfeGYM6Uv",
        "outputId": "f1a1a0db-a3d8-497c-f6be-71c9cc404ff9"
      },
      "source": [
        "print('Size of input vocab : ', len(Text.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Text.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  22130\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [('.', 13325), (',', 11377), ('the', 9794), ('a', 7146), ('of', 7129), ('and', 7015), ('-', 5275), ('to', 5038), (\"'\", 3926), ('is', 3445)]\n",
            "Labels :  defaultdict(None, {0: 0, 2: 1, 1: 2, 3: 3, -1: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwjD2-ebTeUX"
      },
      "source": [
        "**Lots of stopwords!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWW221gTpNs"
      },
      "source": [
        "Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, which is almost, but not quite, like the data loader we used on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqMhMoDUDmn"
      },
      "source": [
        "But at first declare the device we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, dev), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.text),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "tokenizer_path = './tokenizer.pkl'\n",
        "with open(tokenizer_path, 'wb') as tokens: \n",
        "    pickle.dump(Text.vocab.stoi, tokens)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AbsQwqkVyAy"
      },
      "source": [
        "## Defining Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PED4HJWH4t"
      },
      "source": [
        "We use the Embedding and LSTM modules in PyTorch to build a simple model for classifying tweets.\n",
        "\n",
        "In this model we create three layers. \n",
        "1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n",
        "2. That’s then fed into a 2 stacked-LSTMs with 100 hidden features (again, we’re compressing down from the 300-dimensional input like we did with images). We are using 2 LSTMs for using the dropout.\n",
        "3. Finally, the output of the LSTM (the final hidden state after processing the incoming tweet) is pushed through a standard fully connected layer with three outputs to correspond to our five possible classes (very negative, negative, very positive, positive, or neutral)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout,pad_idx):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim,padding_idx = pad_idx)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Text.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 256\n",
        "num_output_nodes = 5\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "PAD_IDX = Text.vocab.stoi[Text.pad_token]\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout, PAD_IDX)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-pOMqzJ3eTv",
        "outputId": "e8fc0a26-b7ea-49d6-bbaa-c423e040ca84"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(22130, 300, padding_idx=1)\n",
            "  (encoder): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
            ")\n",
            "The model has 7,738,013 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfsilWoWvgmW",
        "outputId": "de5ae6f5-943f-4ec6-e8b6-946a326e75bf"
      },
      "source": [
        "pretrained_embeddings = Text.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([22130, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLmyKqqrvkXl",
        "outputId": "6853361f-1db0-46da-eb94-baa4794b499b"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0166, -0.4668,  2.0909,  ...,  0.3555, -1.2744,  0.5221],\n",
              "        [-1.6279,  1.1723,  0.0272,  ..., -0.5068,  0.5402, -0.6818],\n",
              "        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
              "        ...,\n",
              "        [ 0.4261, -0.1805,  0.1000,  ...,  0.1763, -0.3132, -0.0590],\n",
              "        [ 0.0206, -0.2081,  0.4568,  ...,  0.4254,  0.2714, -0.1388],\n",
              "        [-0.0244, -1.1009, -0.4874,  ..., -0.2397,  0.8099,  0.6723]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVds05Wavnpp",
        "outputId": "05e78130-15e3-4338-c90d-bc5f4a4cb463"
      },
      "source": [
        "UNK_IDX = Text.vocab.stoi[Text.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(embedding_dim)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
            "        ...,\n",
            "        [ 0.4261, -0.1805,  0.1000,  ...,  0.1763, -0.3132, -0.0590],\n",
            "        [ 0.0206, -0.2081,  0.4568,  ...,  0.4254,  0.2714, -0.1388],\n",
            "        [-0.0244, -1.1009, -0.4874,  ..., -0.2397,  0.8099,  0.6723]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXajorf5Xz7t"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrE9RpMtZ1Vs"
      },
      "source": [
        "First define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VCJtNb3Zt8w"
      },
      "source": [
        "The main thing to be aware of in this new training loop is that we have to reference `batch.tweets` and `batch.labels` to get the particular fields we’re interested in; they don’t fall out quite as nicely from the enumerator as they do in torchvision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WjEPLKsAiS_"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZcHhkkvAsCt"
      },
      "source": [
        "**Evaluation Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6LJFW7HaJoV"
      },
      "source": [
        "**Let's Train and Evaluate the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq330XlnaEU9",
        "outputId": "f6f3b95a-32f5-4b3a-9f0f-7be01f800b7a"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "train_loss_trend=[]\n",
        "valid_loss_trend=[]\n",
        "train_acc_trend=[]\n",
        "valid_acc_trend=[]\n",
        "model_path='./saved_weights.pt'\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    train_loss_trend.append(train_loss)\n",
        "    train_acc_trend.append(train_acc)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    valid_loss_trend.append(valid_loss)\n",
        "    valid_acc_trend.append(valid_acc)\n",
        "\n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "    print('\\tEpoch No: ', epoch)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399270/400000 [00:50<00:00, 11551.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tEpoch No:  0\n",
            "\tTrain Loss: 1.563 | Train Acc: 31.18%\n",
            "\t Val. Loss: 1.533 |  Val. Acc: 35.39% \n",
            "\n",
            "\tEpoch No:  1\n",
            "\tTrain Loss: 1.502 | Train Acc: 38.31%\n",
            "\t Val. Loss: 1.489 |  Val. Acc: 40.07% \n",
            "\n",
            "\tEpoch No:  2\n",
            "\tTrain Loss: 1.463 | Train Acc: 43.07%\n",
            "\t Val. Loss: 1.476 |  Val. Acc: 41.42% \n",
            "\n",
            "\tEpoch No:  3\n",
            "\tTrain Loss: 1.413 | Train Acc: 48.70%\n",
            "\t Val. Loss: 1.455 |  Val. Acc: 43.79% \n",
            "\n",
            "\tEpoch No:  4\n",
            "\tTrain Loss: 1.366 | Train Acc: 53.94%\n",
            "\t Val. Loss: 1.478 |  Val. Acc: 40.80% \n",
            "\n",
            "\tEpoch No:  5\n",
            "\tTrain Loss: 1.317 | Train Acc: 59.10%\n",
            "\t Val. Loss: 1.429 |  Val. Acc: 46.54% \n",
            "\n",
            "\tEpoch No:  6\n",
            "\tTrain Loss: 1.267 | Train Acc: 64.45%\n",
            "\t Val. Loss: 1.418 |  Val. Acc: 47.69% \n",
            "\n",
            "\tEpoch No:  7\n",
            "\tTrain Loss: 1.223 | Train Acc: 68.64%\n",
            "\t Val. Loss: 1.412 |  Val. Acc: 47.80% \n",
            "\n",
            "\tEpoch No:  8\n",
            "\tTrain Loss: 1.192 | Train Acc: 71.84%\n",
            "\t Val. Loss: 1.412 |  Val. Acc: 48.35% \n",
            "\n",
            "\tEpoch No:  9\n",
            "\tTrain Loss: 1.159 | Train Acc: 75.20%\n",
            "\t Val. Loss: 1.414 |  Val. Acc: 48.02% \n",
            "\n",
            "\tEpoch No:  10\n",
            "\tTrain Loss: 1.134 | Train Acc: 77.66%\n",
            "\t Val. Loss: 1.406 |  Val. Acc: 48.66% \n",
            "\n",
            "\tEpoch No:  11\n",
            "\tTrain Loss: 1.112 | Train Acc: 79.80%\n",
            "\t Val. Loss: 1.394 |  Val. Acc: 50.24% \n",
            "\n",
            "\tEpoch No:  12\n",
            "\tTrain Loss: 1.097 | Train Acc: 81.21%\n",
            "\t Val. Loss: 1.399 |  Val. Acc: 49.60% \n",
            "\n",
            "\tEpoch No:  13\n",
            "\tTrain Loss: 1.087 | Train Acc: 81.99%\n",
            "\t Val. Loss: 1.389 |  Val. Acc: 50.59% \n",
            "\n",
            "\tEpoch No:  14\n",
            "\tTrain Loss: 1.076 | Train Acc: 83.10%\n",
            "\t Val. Loss: 1.399 |  Val. Acc: 49.65% \n",
            "\n",
            "\tEpoch No:  15\n",
            "\tTrain Loss: 1.071 | Train Acc: 83.58%\n",
            "\t Val. Loss: 1.384 |  Val. Acc: 51.25% \n",
            "\n",
            "\tEpoch No:  16\n",
            "\tTrain Loss: 1.061 | Train Acc: 84.43%\n",
            "\t Val. Loss: 1.386 |  Val. Acc: 50.86% \n",
            "\n",
            "\tEpoch No:  17\n",
            "\tTrain Loss: 1.055 | Train Acc: 85.11%\n",
            "\t Val. Loss: 1.389 |  Val. Acc: 50.29% \n",
            "\n",
            "\tEpoch No:  18\n",
            "\tTrain Loss: 1.051 | Train Acc: 85.48%\n",
            "\t Val. Loss: 1.373 |  Val. Acc: 52.22% \n",
            "\n",
            "\tEpoch No:  19\n",
            "\tTrain Loss: 1.048 | Train Acc: 85.79%\n",
            "\t Val. Loss: 1.378 |  Val. Acc: 51.69% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hMOi6rIXwZ14",
        "outputId": "2c5b1f26-ce06-4d09-e2a0-578560a4a2b9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_trend,label='train loss',color=\"red\")\n",
        "plt.plot(valid_loss_trend,label='validation loss ',color=\"blue\")\n",
        "plt.title(\"Train and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qMZfpFHwGnx"
      },
      "source": [
        "\n",
        "**Let's Test the Model**\n",
        "\n",
        "The model will be evaluated with the model test data that was not used for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2PQw6R2xgdx"
      },
      "source": [
        "example_test=[data.Example.fromlist([data_dict['test'].text[i],data_dict['test'].label[i]],fields) for i in range (data_dict['test'].shape[0])]\n",
        "test = data.Dataset(example_test, fields)\n",
        "test_iterator=data.BucketIterator(test,batch_size=32,\n",
        "                                  sort_key = lambda x: len(x.text),\n",
        "                                  sort_within_batch=True,device=device)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n3T0jMcwL5R",
        "outputId": "5db63bbc-b37b-4701-a8f4-405d3a38f0e4"
      },
      "source": [
        "model.load_state_dict(torch.load(model_path))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.368 | Test Acc: 52.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P95DZkBNyhw4"
      },
      "source": [
        "**Let's predict!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUWQN7uAntLk",
        "outputId": "222b861d-4333-4fbb-8cb3-a00124b9517d"
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "\n",
            "\u001b[38;5;1m✘ No compatible model found for 'en_core_web_trf' (spaCy v2.2.4).\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJQhZSbFylPo"
      },
      "source": [
        "model.load_state_dict(torch.load(model_path));\n",
        "model.eval();\n",
        "tokenizer_file = open(tokenizer_path, 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "# load trf instead of base 'en' for greater accuracy\n",
        "nlp = spacy.load('en') \n",
        "\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    #very negative to very positive (- -, -, 0, +, ++)\n",
        "    #Labels :  defaultdict(None, {3: 0, 1: 1, 2: 2, 4: 3, 0: 4})\n",
        "    \n",
        "    categories = {3: \"very negative\", 1:\"negative\", 2:\"Neutral\",4:\"positive\",0:\"very positive\"}\n",
        "    \n",
        "    # tokenize the text \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(text)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3BExxED0Iww"
      },
      "source": [
        "###Predict Sentiment###\n",
        "The sentiment is predicted on unseen data, which was never part of the dev, train, test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y7WvOj6uyz6_",
        "outputId": "1d84de5d-8289-4c30-9851-53af27db36f0"
      },
      "source": [
        "# review of mission impossible 5\n",
        "predict_sentiment(\"Make no mistake, this predictable movie is clearly part of the Mission: Impossible franchise -- by which we mean it checks off all the usual boxes.\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'very positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3TDESIEuzHGn",
        "outputId": "8fcaecc3-15b5-44d9-daab-972e7468cb00"
      },
      "source": [
        "# review of minari\n",
        "predict_sentiment(\"Minari is deeply rooted in the earth, a wellspring of both hope and pain, of boundless promise and terrifying disaster.\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-D_9EwqCzasf",
        "outputId": "dfe157ce-fcb2-4aab-a9c5-7033207a4560"
      },
      "source": [
        "# review of godzilla vs kong\n",
        "predict_sentiment(\"In a patchwork production full of bad ideas poorly executed, Jia also embodies the story’s only good idea.\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M26zaohKz0ko",
        "outputId": "db2af579-9615-4707-9155-3d6aa2ecf2d4"
      },
      "source": [
        "# review of lunch box\n",
        "predict_sentiment(\"Irrfan leads the way, underplayed, yet lasting, like a cardamom between your lips.\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HGXqOxBHz_X_",
        "outputId": "4f71868d-b371-49d6-f2ef-65c12c46de93"
      },
      "source": [
        "# review of avengers endgame\n",
        "predict_sentiment(\"The Russo brothers' poignant, powerful finale more than lives up to the hype: It's a thrilling conclusion and a deeply emotional exploration of loss and love, duty and honor, friendship and family.\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nHhYZu6B0cyw",
        "outputId": "af2b61ca-a21f-4017-d9a7-7bc1b38bedae"
      },
      "source": [
        "# review of godfather\n",
        "predict_sentiment(\"With performances, style and substance to savour, this shows how it is possible to smash box office records without being mindless.\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SLqSlz7q0kwO",
        "outputId": "8471eee5-8185-484f-b09e-bbac9af2a11a"
      },
      "source": [
        "# review of saving private ryan\n",
        "predict_sentiment(\"Uncompromising, powerful war movie that does not pull any punches. Pefectly balances the inhumanity of war and the humanity of its protagonists. Devastating and essential viewing.\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}